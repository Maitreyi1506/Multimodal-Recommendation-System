{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7865325,"sourceType":"datasetVersion","datasetId":4614328}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-19T08:59:03.037316Z","iopub.execute_input":"2024-03-19T08:59:03.037650Z","iopub.status.idle":"2024-03-19T08:59:04.179996Z","shell.execute_reply.started":"2024-03-19T08:59:03.037621Z","shell.execute_reply":"2024-03-19T08:59:04.179179Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cross-domain-recommendation/dataset/leak_stats.py\n/kaggle/input/cross-domain-recommendation/dataset/read_file.py\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/validdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/Blist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/testdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/traindata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/validdata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/Alist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/testdata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/traindata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Food-Kitchen/userlist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/validdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/Blist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/testdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/traindata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/validdata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/Alist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/testdata.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/traindata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Movie-Book/userlist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/validdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/Blist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/testdata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/Alist.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/traindata_new.txt\n/kaggle/input/cross-domain-recommendation/dataset/Entertainment-Education/userlist.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GNN Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.nn.modules.module import Module\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:04.181774Z","iopub.execute_input":"2024-03-19T08:59:04.182451Z","iopub.status.idle":"2024-03-19T08:59:08.621802Z","shell.execute_reply.started":"2024-03-19T08:59:04.182424Z","shell.execute_reply":"2024-03-19T08:59:08.620801Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class GCNLayer(nn.Module):\n    \"\"\"\n        GCN Module layer\n    \"\"\"\n    def __init__(self, opt):\n        super(GCNLayer, self).__init__()\n        self.opt=opt\n        self.dropout = opt[\"dropout\"]\n        self.layer_number = opt[\"GNN\"]\n\n        self.encoder = []\n        for i in range(self.layer_number):\n            self.encoder.append(GNN(\n                nfeat=opt[\"hidden_units\"],\n                nhid=opt[\"hidden_units\"],\n                dropout=opt[\"dropout\"],\n                alpha=opt[\"leakey\"]))\n\n        self.encoder = nn.ModuleList(self.encoder)\n\n    def forward(self, fea, adj):\n        learn_fea = fea\n        tmp_fea = fea\n        for layer in self.encoder:\n            learn_fea = F.dropout(learn_fea, self.dropout, training=self.training)\n            learn_fea = layer(learn_fea, adj)\n            tmp_fea = tmp_fea + learn_fea\n        return tmp_fea / (self.layer_number + 1)\n\n\nclass GNN(nn.Module):\n    def __init__(self, nfeat, nhid, dropout, alpha):\n        super(GNN, self).__init__()\n        self.gc1 = GraphConvolution(nfeat, nhid)\n        self.dropout = dropout\n        self.leakyrelu = nn.LeakyReLU(alpha)\n\n    def forward(self, x, adj):\n        x = self.gc1(x, adj)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.623094Z","iopub.execute_input":"2024-03-19T08:59:08.623456Z","iopub.status.idle":"2024-03-19T08:59:08.634834Z","shell.execute_reply.started":"2024-03-19T08:59:08.623433Z","shell.execute_reply":"2024-03-19T08:59:08.633853Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class GraphConvolution(Module):\n    def __init__(self, in_features, out_features, bias=True):\n        super(GraphConvolution, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        # self.weight = self.glorot_init(in_features, out_features)\n        if bias:\n            self.bias = nn.Parameter(torch.FloatTensor(out_features))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        if self.bias is not None:\n            self.bias.data.uniform_(-stdv, stdv)\n\n    def glorot_init(self, input_dim, output_dim):\n        init_range = np.sqrt(6.0 / (input_dim + output_dim))\n        initial = torch.rand(input_dim, output_dim) * 2 * init_range - init_range\n        return nn.Parameter(initial / 2)\n\n    def forward(self, input, adj):\n        support = input\n        output = torch.spmm(adj, support)\n        if self.bias is not None:\n            return output + self.bias\n        else:\n            return output\n\n    def __repr__(self):\n        return self.__class__.__name__ + ' (' \\\n               + str(self.in_features) + ' -> ' \\\n               + str(self.out_features) + ')'","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.637834Z","iopub.execute_input":"2024-03-19T08:59:08.638120Z","iopub.status.idle":"2024-03-19T08:59:08.656218Z","shell.execute_reply.started":"2024-03-19T08:59:08.638097Z","shell.execute_reply":"2024-03-19T08:59:08.655402Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.657359Z","iopub.execute_input":"2024-03-19T08:59:08.657656Z","iopub.status.idle":"2024-03-19T08:59:08.670543Z","shell.execute_reply.started":"2024-03-19T08:59:08.657633Z","shell.execute_reply":"2024-03-19T08:59:08.669711Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n    def __init__(self, n_in,n_out):\n        super(Discriminator, self).__init__()\n        self.f_k = nn.Bilinear(n_in, n_out, 1)\n        for m in self.modules():\n            self.weights_init(m)\n\n    def weights_init(self, m):\n        if isinstance(m, nn.Bilinear):\n            torch.nn.init.xavier_uniform_(m.weight.data)\n            if m.bias is not None:\n                m.bias.data.fill_(0.0)\n\n    def forward(self, S, node, s_bias=None):\n        score = self.f_k(node, S)\n        if s_bias is not None:\n            score += s_bias\n        return score","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.671664Z","iopub.execute_input":"2024-03-19T08:59:08.671974Z","iopub.status.idle":"2024-03-19T08:59:08.681163Z","shell.execute_reply.started":"2024-03-19T08:59:08.671952Z","shell.execute_reply":"2024-03-19T08:59:08.680313Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PointWiseFeedForward(torch.nn.Module):\n    def __init__(self, hidden_units, dropout_rate):\n\n        super(PointWiseFeedForward, self).__init__()\n        self.gru1 = torch.nn.GRU(hidden_units, hidden_units, batch_first=True)\n#         self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n        self.relu = torch.nn.ReLU()\n        self.gru2 = torch.nn.GRU(hidden_units, hidden_units, batch_first=True)\n#         self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n\n    def forward(self, inputs):\n#         print(f\"Shape of inputs {inputs.shape}\")\n        outputs = self.dropout2(self.gru2(self.relu(self.dropout1(self.gru1(inputs)[0])))[0])\n#         outputs = outputs.transpose(-1, -2) \n        outputs += inputs\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.682351Z","iopub.execute_input":"2024-03-19T08:59:08.683234Z","iopub.status.idle":"2024-03-19T08:59:08.694436Z","shell.execute_reply.started":"2024-03-19T08:59:08.683210Z","shell.execute_reply":"2024-03-19T08:59:08.693510Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ATTENTION(torch.nn.Module):\n    def __init__(self, opt):\n        super(ATTENTION, self).__init__()\n        self.opt = opt\n        self.emb_dropout = torch.nn.Dropout(p=self.opt[\"dropout\"])\n        self.pos_emb = torch.nn.Embedding(self.opt[\"maxlen\"], self.opt[\"hidden_units\"], padding_idx=0)  # TO IMPROVE\n        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n        self.attention_layernorms = torch.nn.ModuleList() # to be Q for self-attention\n        self.attention_layers = torch.nn.ModuleList()\n        self.forward_layernorms = torch.nn.ModuleList()\n        self.forward_layers = torch.nn.ModuleList()\n\n        self.last_layernorm = torch.nn.LayerNorm(self.opt[\"hidden_units\"], eps=1e-8)\n\n        for _ in range(self.opt[\"num_blocks\"]):\n            new_attn_layernorm = torch.nn.LayerNorm(self.opt[\"hidden_units\"], eps=1e-8)\n            self.attention_layernorms.append(new_attn_layernorm)\n\n            new_attn_layer =  torch.nn.MultiheadAttention(self.opt[\"hidden_units\"],\n                                                            self.opt[\"num_heads\"],\n                                                            self.opt[\"dropout\"])\n            self.attention_layers.append(new_attn_layer)\n\n            new_fwd_layernorm = torch.nn.LayerNorm(self.opt[\"hidden_units\"], eps=1e-8)\n            self.forward_layernorms.append(new_fwd_layernorm)\n\n            new_fwd_layer = PointWiseFeedForward(self.opt[\"hidden_units\"], self.opt[\"dropout\"])\n            self.forward_layers.append(new_fwd_layer)\n\n    def forward(self, seqs_data, seqs, position):\n        # positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1])\n        seqs += self.pos_emb(position)\n        seqs = self.emb_dropout(seqs)\n\n        timeline_mask = torch.BoolTensor(seqs_data.cpu() == self.opt[\"itemnum\"] - 1)\n        if self.opt[\"cuda\"]:\n            timeline_mask = timeline_mask.cuda()\n        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim\n\n        tl = seqs.shape[1] # time dim len for enforce causality\n        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool))\n        if self.opt[\"cuda\"]:\n            attention_mask = attention_mask.cuda()\n\n        for i in range(len(self.attention_layers)):\n            seqs = torch.transpose(seqs, 0, 1)\n            Q = self.attention_layernorms[i](seqs)\n            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs,\n                                            attn_mask=attention_mask)\n                                            # key_padding_mask=timeline_mask\n                                            # need_weights=False) this arg do not work?\n            seqs = Q + mha_outputs\n            seqs = torch.transpose(seqs, 0, 1)\n\n            seqs = self.forward_layernorms[i](seqs)\n            seqs = self.forward_layers[i](seqs)\n            seqs *=  ~timeline_mask.unsqueeze(-1)\n\n        log_feats = self.last_layernorm(seqs) # (U, T, C) -> (U, -1, C)\n\n        return log_feats","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.695690Z","iopub.execute_input":"2024-03-19T08:59:08.696165Z","iopub.status.idle":"2024-03-19T08:59:08.716335Z","shell.execute_reply.started":"2024-03-19T08:59:08.696140Z","shell.execute_reply":"2024-03-19T08:59:08.715396Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class C2DSR(torch.nn.Module):\n    def __init__(self, opt, adj, adj_single):\n        super(C2DSR, self).__init__()\n        self.opt = opt\n        self.item_emb_X = torch.nn.Embedding(self.opt[\"itemnum\"], self.opt[\"hidden_units\"],\n                                           padding_idx=self.opt[\"itemnum\"] - 1)\n        self.item_emb_Y = torch.nn.Embedding(self.opt[\"itemnum\"], self.opt[\"hidden_units\"],\n                                           padding_idx=self.opt[\"itemnum\"] - 1)\n        self.item_emb = torch.nn.Embedding(self.opt[\"itemnum\"], self.opt[\"hidden_units\"],\n                                           padding_idx=self.opt[\"itemnum\"] - 1)\n        self.GNN_encoder_X = GCNLayer(opt)\n        self.GNN_encoder_Y = GCNLayer(opt)\n        self.GNN_encoder = GCNLayer(opt)\n        self.adj = adj\n        self.adj_single = adj_single\n\n        self.D_X = Discriminator(self.opt[\"hidden_units\"], self.opt[\"hidden_units\"])\n        self.D_Y = Discriminator(self.opt[\"hidden_units\"], self.opt[\"hidden_units\"])\n\n        self.lin_X = nn.Linear(self.opt[\"hidden_units\"], self.opt[\"source_item_num\"])\n        self.lin_Y = nn.Linear(self.opt[\"hidden_units\"], self.opt[\"target_item_num\"])\n        self.lin_PAD = nn.Linear(self.opt[\"hidden_units\"], 1)\n        self.encoder = ATTENTION(opt)\n        self.encoder_X = ATTENTION(opt)\n        self.encoder_Y = ATTENTION(opt)\n\n        self.source_item_index = torch.arange(0, self.opt[\"source_item_num\"], 1)\n        self.target_item_index = torch.arange(self.opt[\"source_item_num\"], self.opt[\"source_item_num\"]+self.opt[\"target_item_num\"], 1)\n        self.item_index = torch.arange(0, self.opt[\"itemnum\"], 1)\n        if self.opt[\"cuda\"]:\n            self.source_item_index = self.source_item_index.cuda()\n            self.target_item_index = self.target_item_index.cuda()\n            self.item_index = self.item_index.cuda()\n\n    def my_index_select_embedding(self, memory, index):\n        tmp = list(index.size()) + [-1]\n        index = index.view(-1)\n        ans = memory(index)\n        ans = ans.view(tmp)\n        return ans\n\n    def my_index_select(self, memory, index):\n        tmp = list(index.size()) + [-1]\n        index = index.view(-1)\n        ans = torch.index_select(memory, 0, index)\n        ans = ans.view(tmp)\n        return ans\n\n    def graph_convolution(self):\n        fea = self.my_index_select_embedding(self.item_emb, self.item_index)\n        fea_X = self.my_index_select_embedding(self.item_emb_X, self.item_index)\n        fea_Y = self.my_index_select_embedding(self.item_emb_Y, self.item_index)\n\n        self.cross_emb = self.GNN_encoder(fea, self.adj)\n        self.single_emb_X = self.GNN_encoder_X(fea_X, self.adj_single)\n        self.single_emb_Y = self.GNN_encoder_Y(fea_Y, self.adj_single)\n\n    def forward(self, o_seqs, x_seqs, y_seqs, position, x_position, y_position):\n        seqs = self.my_index_select(self.cross_emb, o_seqs) + self.item_emb(o_seqs)\n        seqs *= self.item_emb.embedding_dim ** 0.5\n        seqs_fea = self.encoder(o_seqs, seqs, position)\n\n        seqs = self.my_index_select(self.single_emb_X, x_seqs) + self.item_emb_X(x_seqs)\n        seqs *= self.item_emb.embedding_dim ** 0.5\n        x_seqs_fea = self.encoder_X(x_seqs, seqs, x_position)\n\n        seqs = self.my_index_select(self.single_emb_Y, y_seqs) + self.item_emb_Y(y_seqs)\n        seqs *= self.item_emb.embedding_dim ** 0.5\n        y_seqs_fea = self.encoder_Y(y_seqs, seqs, y_position)\n\n        return seqs_fea, x_seqs_fea, y_seqs_fea\n\n    def false_forward(self, false_seqs, position):\n        seqs = self.my_index_select(self.cross_emb, false_seqs) + self.item_emb(false_seqs)\n        seqs *= self.item_emb.embedding_dim ** 0.5\n        false_seqs_fea = self.encoder(false_seqs, seqs, position)\n        return false_seqs_fea","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.717703Z","iopub.execute_input":"2024-03-19T08:59:08.717955Z","iopub.status.idle":"2024-03-19T08:59:08.740387Z","shell.execute_reply.started":"2024-03-19T08:59:08.717934Z","shell.execute_reply":"2024-03-19T08:59:08.739182Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Graph Maker","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport scipy.sparse as sp\nimport torch\nimport codecs\nimport json\nimport copy","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.745375Z","iopub.execute_input":"2024-03-19T08:59:08.745765Z","iopub.status.idle":"2024-03-19T08:59:08.916530Z","shell.execute_reply.started":"2024-03-19T08:59:08.745731Z","shell.execute_reply":"2024-03-19T08:59:08.915307Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def normalize(mx):\n    \"\"\"Row-normalize sparse matrix\"\"\"\n    rowsum = np.array(mx.sum(1))\n    r_inv = np.power(rowsum, -1).flatten()\n    r_inv[np.isinf(r_inv)] = 0.\n    r_mat_inv = sp.diags(r_inv)\n    mx = r_mat_inv.dot(mx)\n    return mx","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.918369Z","iopub.execute_input":"2024-03-19T08:59:08.919107Z","iopub.status.idle":"2024-03-19T08:59:08.941690Z","shell.execute_reply.started":"2024-03-19T08:59:08.919057Z","shell.execute_reply":"2024-03-19T08:59:08.940458Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n    indices = torch.from_numpy(\n        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n    values = torch.from_numpy(sparse_mx.data)\n    shape = torch.Size(sparse_mx.shape)\n    return torch.sparse.FloatTensor(indices, values, shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.942601Z","iopub.execute_input":"2024-03-19T08:59:08.942900Z","iopub.status.idle":"2024-03-19T08:59:08.954112Z","shell.execute_reply.started":"2024-03-19T08:59:08.942869Z","shell.execute_reply":"2024-03-19T08:59:08.952926Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class GraphMaker(object):\n    def __init__(self, opt, filename):\n        self.opt = opt\n        self.user = set()\n        self.item = set()\n        train_data = []\n\n        def takeSecond(elem):\n            return elem[1]\n        with codecs.open(filename, \"r\", encoding=\"utf-8\") as infile:\n            for id, line in enumerate(infile):\n                res = []\n                line = line.strip().split(\"\\t\")[2:]\n                for w in line:\n                    w = w.split(\"|\")\n                    res.append((int(w[0]), int(w[1])))\n                res.sort(key=takeSecond)\n                res_2 = []\n                for r in res:\n                    res_2.append(r[0])\n                train_data.append(res_2)\n\n        self.raw_data = train_data\n        self.adj, self.adj_single = self.preprocess(train_data, opt)\n\n    def preprocess(self,data,opt):\n\n        VV_edges = []\n        VV_edges_single = []\n\n        real_adj = {}\n\n        for seq in data:\n            source = -1\n            target = -1\n            pre = -1\n            for d in seq:\n                if d not in real_adj:\n                    real_adj[d] = set()\n                if d < self.opt[\"source_item_num\"]:\n                    if source is not -1:\n                        if d in real_adj[source]:\n                            continue\n                        else:\n                            VV_edges_single.append([source, d])\n                    source = d\n\n                else :\n                    if target is not -1:\n                        if d in real_adj[target]:\n                            continue\n                        else:\n                            VV_edges_single.append([target, d])\n                    target = d\n\n                if pre is not -1:\n                    if d in real_adj[pre]:\n                        continue\n                    VV_edges.append([pre, d])\n                pre=d\n\n        VV_edges = np.array(VV_edges)\n        VV_edges_single = np.array(VV_edges_single)\n        adj = sp.coo_matrix((np.ones(VV_edges.shape[0]), (VV_edges[:, 0], VV_edges[:, 1])),\n                               shape=(opt[\"itemnum\"], opt[\"itemnum\"]),\n                               dtype=np.float32)\n        adj_single = sp.coo_matrix((np.ones(VV_edges_single.shape[0]), (VV_edges_single[:, 0], VV_edges_single[:, 1])),shape=(opt[\"itemnum\"], opt[\"itemnum\"]),dtype=np.float32)\n\n        adj = normalize(adj)\n        adj_single = normalize(adj_single)\n        adj = sparse_mx_to_torch_sparse_tensor(adj)\n        adj_single = sparse_mx_to_torch_sparse_tensor(adj_single)\n\n        print(\"real graph loaded!\")\n        return adj, adj_single","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.955157Z","iopub.execute_input":"2024-03-19T08:59:08.955821Z","iopub.status.idle":"2024-03-19T08:59:08.974177Z","shell.execute_reply.started":"2024-03-19T08:59:08.955791Z","shell.execute_reply":"2024-03-19T08:59:08.973319Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:56: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:56: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n/tmp/ipykernel_35/4294224670.py:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if source is not -1:\n/tmp/ipykernel_35/4294224670.py:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if target is not -1:\n/tmp/ipykernel_35/4294224670.py:56: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if pre is not -1:\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Helper","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport sys","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.975108Z","iopub.execute_input":"2024-03-19T08:59:08.975645Z","iopub.status.idle":"2024-03-19T08:59:08.985273Z","shell.execute_reply.started":"2024-03-19T08:59:08.975615Z","shell.execute_reply":"2024-03-19T08:59:08.984370Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def check_dir(d):\n    if not os.path.exists(d):\n        print(\"Directory {} does not exist. Exit.\".format(d))\n        exit(1)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.986638Z","iopub.execute_input":"2024-03-19T08:59:08.986918Z","iopub.status.idle":"2024-03-19T08:59:08.995254Z","shell.execute_reply.started":"2024-03-19T08:59:08.986877Z","shell.execute_reply":"2024-03-19T08:59:08.994502Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def check_files(files):\n    for f in files:\n        if f is not None and not os.path.exists(f):\n            print(\"File {} does not exist. Exit.\".format(f))\n            exit(1)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:08.996246Z","iopub.execute_input":"2024-03-19T08:59:08.996500Z","iopub.status.idle":"2024-03-19T08:59:09.004580Z","shell.execute_reply.started":"2024-03-19T08:59:08.996479Z","shell.execute_reply":"2024-03-19T08:59:09.003783Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def ensure_dir(d, verbose=True):\n    if not os.path.exists(d):\n        if verbose:\n            print(\"Directory {} do not exist; creating...\".format(d))\n        os.makedirs(d)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.005907Z","iopub.execute_input":"2024-03-19T08:59:09.006572Z","iopub.status.idle":"2024-03-19T08:59:09.015067Z","shell.execute_reply.started":"2024-03-19T08:59:09.006521Z","shell.execute_reply":"2024-03-19T08:59:09.014155Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def save_config(config, path, verbose=True):\n    with open(path, 'w') as outfile:\n        json.dump(config, outfile, indent=2)\n    if verbose:\n        print(\"Config saved to file {}\".format(path))\n    return config","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.016224Z","iopub.execute_input":"2024-03-19T08:59:09.016777Z","iopub.status.idle":"2024-03-19T08:59:09.024580Z","shell.execute_reply.started":"2024-03-19T08:59:09.016745Z","shell.execute_reply":"2024-03-19T08:59:09.023797Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def load_config(path, verbose=True):\n    with open(path) as f:\n        config = json.load(f)\n    if verbose:\n        print(\"Config loaded from file {}\".format(path))\n    return config","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.028173Z","iopub.execute_input":"2024-03-19T08:59:09.029121Z","iopub.status.idle":"2024-03-19T08:59:09.034273Z","shell.execute_reply.started":"2024-03-19T08:59:09.029085Z","shell.execute_reply":"2024-03-19T08:59:09.033371Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def print_config(config):\n    info = \"Running with the following configs:\\n\"\n    for k, v in config.items():\n        info += \"\\t{} : {}\\n\".format(k, str(v))\n    print(\"\\n\" + info + \"\\n\")\n    return","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.035006Z","iopub.execute_input":"2024-03-19T08:59:09.035275Z","iopub.status.idle":"2024-03-19T08:59:09.047917Z","shell.execute_reply.started":"2024-03-19T08:59:09.035253Z","shell.execute_reply":"2024-03-19T08:59:09.047068Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class FileLogger(object):\n    \"\"\"\n    A file logger that opens the file periodically and write to it.\n    \"\"\"\n\n    def __init__(self, filename, header=None):\n        self.filename = filename\n        if os.path.exists(filename):\n            # remove the old file\n            os.remove(filename)\n        if header is not None:\n            with open(filename, 'w') as out:\n                print(header, file=out)\n\n    def log(self, message):\n        with open(self.filename, 'a') as out:\n            print(message, file=out)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.049072Z","iopub.execute_input":"2024-03-19T08:59:09.049365Z","iopub.status.idle":"2024-03-19T08:59:09.058098Z","shell.execute_reply.started":"2024-03-19T08:59:09.049342Z","shell.execute_reply":"2024-03-19T08:59:09.057207Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Loader","metadata":{}},{"cell_type":"code","source":"import json\nimport random\nimport torch\nimport numpy as np\nimport codecs\nimport copy\nimport pdb","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.059512Z","iopub.execute_input":"2024-03-19T08:59:09.059819Z","iopub.status.idle":"2024-03-19T08:59:09.069281Z","shell.execute_reply.started":"2024-03-19T08:59:09.059796Z","shell.execute_reply":"2024-03-19T08:59:09.068278Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class DataLoader(object):\n    \"\"\"\n    Load data from json files, preprocess and prepare batches.\n    \"\"\"\n    def __init__(self, filename, batch_size, opt, evaluation):\n        self.batch_size = batch_size\n        self.opt = opt\n        self.eval = evaluation\n        self.filename  = filename\n        # ************* item_id *****************\n        #/kaggle/input/cross-domain-recommendation\n        opt[\"source_item_num\"] = self.read_item(\"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/Alist.txt\")\n        opt[\"target_item_num\"] = self.read_item(\"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/Blist.txt\")\n\n        # ************* sequential data *****************\n\n        source_train_data = \"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/traindata_new.txt\"\n        source_valid_data = \"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/validdata_new.txt\"\n        source_test_data = \"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/testdata_new.txt\"\n\n        if evaluation < 0:\n            self.train_data = self.read_train_data(source_train_data)\n            data = self.preprocess()\n        elif evaluation == 2:\n            self.test_data = self.read_test_data(source_valid_data)\n            data = self.preprocess_for_predict()\n        else :\n            self.test_data = self.read_test_data(source_test_data)\n            data = self.preprocess_for_predict()\n\n        # shuffle for training\n        if evaluation == -1:\n            indices = list(range(len(data)))\n            random.shuffle(indices)\n            data = [data[i] for i in indices]\n            if batch_size > len(data):\n                batch_size = len(data)\n                self.batch_size = batch_size\n            if len(data)%batch_size != 0:\n                data += data[:batch_size]\n            data = data[: (len(data)//batch_size) * batch_size]\n        else :\n            batch_size = 2048\n        self.num_examples = len(data)\n\n        # chunk into batches\n        data = [data[i:i+batch_size] for i in range(0, len(data), batch_size)]\n        self.data = data\n\n    def read_item(self, fname):\n        item_number = 0\n        with codecs.open(fname, \"r\", encoding=\"utf-8\") as fr:\n            for line in fr:\n                item_number += 1\n        return item_number\n\n    def read_train_data(self, train_file):\n        def takeSecond(elem):\n            return elem[1]\n        with codecs.open(train_file, \"r\", encoding=\"utf-8\") as infile:\n            train_data = []\n            for id, line in enumerate(infile):\n                res = []\n\n                line = line.strip().split(\"\\t\")[2:]\n                for w in line:\n                    w = w.split(\"|\")\n                    res.append((int(w[0]), int(w[1])))\n                res.sort(key=takeSecond)\n                res_2 = []\n                for r in res:\n                    res_2.append(r[0])\n                train_data.append(res_2)\n\n        return train_data\n\n    def read_test_data(self, test_file):\n        def takeSecond(elem):\n            return elem[1]\n        with codecs.open(test_file, \"r\", encoding=\"utf-8\") as infile:\n            test_data = []\n            for id, line in enumerate(infile):\n                res = []\n                line = line.strip().split(\"\\t\")[2:]\n                for w in line:\n                    w = w.split(\"|\")\n                    res.append((int(w[0]), int(w[1])))\n\n                res.sort(key=takeSecond)\n\n                res_2 = []\n                for r in res[:-1]:\n                    res_2.append(r[0])\n\n                if res[-1][0] >= self.opt[\"source_item_num\"]: # denoted the corresponding validation/test entry\n                    test_data.append([res_2, 1, res[-1][0]])\n                else :\n                    test_data.append([res_2, 0, res[-1][0]])\n        return test_data\n\n    def preprocess_for_predict(self):\n\n        if \"Enter\" in self.filename:\n            max_len = 30\n            self.opt[\"maxlen\"] = 30\n        else:\n            max_len = 15\n            self.opt[\"maxlen\"] = 15\n\n        processed=[]\n        for d in self.test_data: # the pad is needed! but to be careful.\n            position = list(range(len(d[0])+1))[1:]\n\n            xd = []\n            xcnt = 1\n            x_position = []\n\n            yd = []\n            ycnt = 1\n            y_position = []\n\n            for w in d[0]:\n                if w < self.opt[\"source_item_num\"]:\n                    xd.append(w)\n                    x_position.append(xcnt)\n                    xcnt += 1\n                    yd.append(self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"])\n                    y_position.append(0)\n\n                else:\n                    xd.append(self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"])\n                    x_position.append(0)\n                    yd.append(w)\n                    y_position.append(ycnt)\n                    ycnt += 1\n\n\n            if len(d[0]) < max_len:\n                position = [0] * (max_len - len(d[0])) + position\n                x_position = [0] * (max_len - len(d[0])) + x_position\n                y_position = [0] * (max_len - len(d[0])) + y_position\n\n                xd = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d[0])) + xd\n                yd = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d[0])) + yd\n                seq = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]]*(max_len - len(d[0])) + d[0]\n\n\n            x_last = -1\n            for id in range(len(x_position)):\n                id += 1\n                if x_position[-id]:\n                    x_last = -id\n                    break\n\n            y_last = -1\n            for id in range(len(y_position)):\n                id += 1\n                if y_position[-id]:\n                    y_last = -id\n                    break\n\n            negative_sample = []\n            for i in range(999):\n                while True:\n                    if d[1] : # in Y domain, the validation/test negative samples\n                        sample = random.randint(0, self.opt[\"target_item_num\"] - 1)\n                        if sample != d[2] - self.opt[\"source_item_num\"]:\n                            negative_sample.append(sample)\n                            break\n                    else : # in X domain, the validation/test negative samples\n                        sample = random.randint(0, self.opt[\"source_item_num\"] - 1)\n                        if sample != d[2]:\n                            negative_sample.append(sample)\n                            break\n\n\n            if d[1]:\n                processed.append([seq, xd, yd, position, x_position, y_position, x_last, y_last, d[1], d[2]-self.opt[\"source_item_num\"], negative_sample])\n            else:\n                processed.append([seq, xd, yd, position, x_position, y_position, x_last, y_last, d[1],\n                                  d[2], negative_sample])\n        return processed\n\n    def preprocess(self):\n\n        def myprint(a):\n            for i in a:\n                print(\"%6d\" % i, end=\"\")\n            print(\"\")\n        \"\"\" Preprocess the data and convert to ids. \"\"\"\n        processed = []\n\n\n        if \"Enter\" in self.filename:\n            max_len = 30\n            self.opt[\"maxlen\"] = 30\n        else:\n            max_len = 15\n            self.opt[\"maxlen\"] = 15\n\n        for d in self.train_data: # the pad is needed! but to be careful.\n\n            ground = copy.deepcopy(d)[1:]\n\n\n            share_x_ground = []\n            share_x_ground_mask = []\n            share_y_ground = []\n            share_y_ground_mask = []\n            for w in ground:\n                if w < self.opt[\"source_item_num\"]:\n                    share_x_ground.append(w)\n                    share_x_ground_mask.append(1)\n                    share_y_ground.append(self.opt[\"target_item_num\"])\n                    share_y_ground_mask.append(0)\n                else:\n                    share_x_ground.append(self.opt[\"source_item_num\"])\n                    share_x_ground_mask.append(0)\n                    share_y_ground.append(w - self.opt[\"source_item_num\"])\n                    share_y_ground_mask.append(1)\n\n\n            d = d[:-1]  # delete the ground truth\n            position = list(range(len(d)+1))[1:]\n            ground_mask = [1] * len(d)\n\n\n\n            xd = []\n            xcnt = 1\n            x_position = []\n\n\n            yd = []\n            ycnt = 1\n            y_position = []\n\n            corru_x = []\n            corru_y = []\n\n            for w in d:\n                if w < self.opt[\"source_item_num\"]:\n                    corru_x.append(w)\n                    xd.append(w)\n                    x_position.append(xcnt)\n                    xcnt += 1\n                    corru_y.append(random.randint(0, self.opt[\"source_item_num\"] - 1))\n                    yd.append(self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"])\n                    y_position.append(0)\n\n                else:\n                    corru_x.append(random.randint(self.opt[\"source_item_num\"], self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"] - 1))\n                    xd.append(self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"])\n                    x_position.append(0)\n                    corru_y.append(w)\n                    yd.append(w)\n                    y_position.append(ycnt)\n                    ycnt += 1\n\n            now = -1\n            x_ground = [self.opt[\"source_item_num\"]] * len(xd) # caution!\n            x_ground_mask = [0] * len(xd)\n            for id in range(len(xd)):\n                id+=1\n                if x_position[-id]:\n                    if now == -1:\n                        now = xd[-id]\n                        if ground[-1] < self.opt[\"source_item_num\"]:\n                            x_ground[-id] = ground[-1]\n                            x_ground_mask[-id] = 1\n                        else:\n                            xd[-id] = self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]\n                            x_position[-id] = 0\n                    else:\n                        x_ground[-id] = now\n                        x_ground_mask[-id] = 1\n                        now = xd[-id]\n            if sum(x_ground_mask) == 0:\n                print(\"pass sequence x\")\n                continue\n\n            now = -1\n            y_ground = [self.opt[\"target_item_num\"]] * len(yd) # caution!\n            y_ground_mask = [0] * len(yd)\n            for id in range(len(yd)):\n                id+=1\n                if y_position[-id]:\n                    if now == -1:\n                        now = yd[-id] - self.opt[\"source_item_num\"]\n                        if ground[-1] > self.opt[\"source_item_num\"]:\n                            y_ground[-id] = ground[-1] - self.opt[\"source_item_num\"]\n                            y_ground_mask[-id] = 1\n                        else:\n                            yd[-id] = self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]\n                            y_position[-id] = 0\n                    else:\n                        y_ground[-id] = now\n                        y_ground_mask[-id] = 1\n                        now = yd[-id] - self.opt[\"source_item_num\"]\n            if sum(y_ground_mask) == 0:\n                print(\"pass sequence y\")\n                continue\n\n            if len(d) < max_len:\n                position = [0] * (max_len - len(d)) + position\n                x_position = [0] * (max_len - len(d)) + x_position\n                y_position = [0] * (max_len - len(d)) + y_position\n\n                ground = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + ground\n                share_x_ground = [self.opt[\"source_item_num\"]] * (max_len - len(d)) + share_x_ground\n                share_y_ground = [self.opt[\"target_item_num\"]] * (max_len - len(d)) + share_y_ground\n                x_ground = [self.opt[\"source_item_num\"]] * (max_len - len(d)) + x_ground\n                y_ground = [self.opt[\"target_item_num\"]] * (max_len - len(d)) + y_ground\n\n                ground_mask = [0] * (max_len - len(d)) + ground_mask\n                share_x_ground_mask = [0] * (max_len - len(d)) + share_x_ground_mask\n                share_y_ground_mask = [0] * (max_len - len(d)) + share_y_ground_mask\n                x_ground_mask = [0] * (max_len - len(d)) + x_ground_mask\n                y_ground_mask = [0] * (max_len - len(d)) + y_ground_mask\n\n                corru_x = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + corru_x\n                corru_y = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + corru_y\n                xd = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + xd\n                yd = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + yd\n                d = [self.opt[\"source_item_num\"] + self.opt[\"target_item_num\"]] * (max_len - len(d)) + d\n            else:\n                print(\"pass\")\n\n            processed.append([d, xd, yd, position, x_position, y_position, ground, share_x_ground, share_y_ground, x_ground, y_ground, ground_mask, share_x_ground_mask, share_y_ground_mask, x_ground_mask, y_ground_mask, corru_x, corru_y])\n        return processed\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, key):\n        \"\"\" Get a batch with index. \"\"\"\n        if not isinstance(key, int):\n            raise TypeError\n        if key < 0 or key >= len(self.data):\n            raise IndexError\n        batch = self.data[key]\n        batch_size = len(batch)\n        if self.eval!=-1:\n            batch = list(zip(*batch))\n            return (torch.LongTensor(batch[0]), torch.LongTensor(batch[1]), torch.LongTensor(batch[2]), torch.LongTensor(batch[3]),torch.LongTensor(batch[4]), torch.LongTensor(batch[5]), torch.LongTensor(batch[6]), torch.LongTensor(batch[7]),torch.LongTensor(batch[8]), torch.LongTensor(batch[9]), torch.LongTensor(batch[10]))\n        else :\n            batch = list(zip(*batch))\n\n            return (torch.LongTensor(batch[0]), torch.LongTensor(batch[1]), torch.LongTensor(batch[2]), torch.LongTensor(batch[3]),torch.LongTensor(batch[4]), torch.LongTensor(batch[5]), torch.LongTensor(batch[6]), torch.LongTensor(batch[7]),torch.LongTensor(batch[8]), torch.LongTensor(batch[9]), torch.LongTensor(batch[10]), torch.LongTensor(batch[11]), torch.LongTensor(batch[12]), torch.LongTensor(batch[13]), torch.LongTensor(batch[14]), torch.LongTensor(batch[15]), torch.LongTensor(batch[16]), torch.LongTensor(batch[17]))\n\n    def __iter__(self):\n        for i in range(self.__len__()):\n            yield self.__getitem__(i)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.071295Z","iopub.execute_input":"2024-03-19T08:59:09.071581Z","iopub.status.idle":"2024-03-19T08:59:09.150947Z","shell.execute_reply.started":"2024-03-19T08:59:09.071550Z","shell.execute_reply":"2024-03-19T08:59:09.150085Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Torch Utils","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.optim.optimizer import Optimizer","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.152219Z","iopub.execute_input":"2024-03-19T08:59:09.152656Z","iopub.status.idle":"2024-03-19T08:59:09.161059Z","shell.execute_reply.started":"2024-03-19T08:59:09.152622Z","shell.execute_reply":"2024-03-19T08:59:09.160162Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class MyAdagrad(Optimizer):\n    \"\"\"My modification of the Adagrad optimizer that allows to specify an initial\n    accumulater value. This mimics the behavior of the default Adagrad implementation\n    in Tensorflow. The default PyTorch Adagrad uses 0 for initial acculmulator value.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-2)\n        lr_decay (float, optional): learning rate decay (default: 0)\n        init_accu_value (float, optional): initial accumulater value.\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n    \"\"\"\n\n    def __init__(self, params, lr=1e-2, lr_decay=0, init_accu_value=0.1, weight_decay=0):\n        defaults = dict(lr=lr, lr_decay=lr_decay, init_accu_value=init_accu_value, \\\n                weight_decay=weight_decay)\n        super(MyAdagrad, self).__init__(params, defaults)\n\n        for group in self.param_groups:\n            for p in group['params']:\n                state = self.state[p]\n                state['step'] = 0\n                state['sum'] = torch.ones(p.data.size()).type_as(p.data) *\\\n                        init_accu_value\n\n    def share_memory(self):\n        for group in self.param_groups:\n            for p in group['params']:\n                state = self.state[p]\n                state['sum'].share_memory_()\n\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n\n                grad = p.grad.data\n                state = self.state[p]\n\n                state['step'] += 1\n\n                if group['weight_decay'] != 0:\n                    if p.grad.data.is_sparse:\n                        raise RuntimeError(\"weight_decay option is not compatible with sparse gradients \")\n                    grad = grad.add(group['weight_decay'], p.data)\n\n                clr = group['lr'] / (1 + (state['step'] - 1) * group['lr_decay'])\n\n                if p.grad.data.is_sparse:\n                    grad = grad.coalesce()  # the update is non-linear so indices must be unique\n                    grad_indices = grad._indices()\n                    grad_values = grad._values()\n                    size = torch.Size([x for x in grad.size()])\n\n                    def make_sparse(values):\n                        constructor = type(p.grad.data)\n                        if grad_indices.dim() == 0 or values.dim() == 0:\n                            return constructor()\n                        return constructor(grad_indices, values, size)\n                    state['sum'].add_(make_sparse(grad_values.pow(2)))\n                    std = state['sum']._sparse_mask(grad)\n                    std_values = std._values().sqrt_().add_(1e-10)\n                    p.data.add_(-clr, make_sparse(grad_values / std_values))\n                else:\n                    state['sum'].addcmul_(1, grad, grad)\n                    std = state['sum'].sqrt().add_(1e-10)\n                    p.data.addcdiv_(-clr, grad, std)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.162284Z","iopub.execute_input":"2024-03-19T08:59:09.162613Z","iopub.status.idle":"2024-03-19T08:59:09.181314Z","shell.execute_reply.started":"2024-03-19T08:59:09.162583Z","shell.execute_reply":"2024-03-19T08:59:09.180390Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_optimizer(name, parameters, lr, l2=0):\n    if name == 'sgd':\n        return torch.optim.SGD(parameters, lr=lr, weight_decay=l2)\n    elif name in ['adagrad', 'myadagrad']:\n        # use my own adagrad to allow for init accumulator value\n        return MyAdagrad(parameters, lr=lr, init_accu_value=0.1, weight_decay=l2)\n    elif name == 'adam':\n        return torch.optim.Adam(parameters, weight_decay=l2, lr=lr, betas=(0.9, 0.98)) # use default lr\n    elif name == 'adamax':\n        return torch.optim.Adamax(parameters, weight_decay=l2) # use default lr\n    elif name == 'adadelta':\n        return torch.optim.Adadelta(parameters, lr=lr, weight_decay=l2)\n    else:\n        raise Exception(\"Unsupported optimizer: {}\".format(name))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.182438Z","iopub.execute_input":"2024-03-19T08:59:09.182734Z","iopub.status.idle":"2024-03-19T08:59:09.195213Z","shell.execute_reply.started":"2024-03-19T08:59:09.182707Z","shell.execute_reply":"2024-03-19T08:59:09.194308Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def change_lr(optimizer, new_lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = new_lr","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.196310Z","iopub.execute_input":"2024-03-19T08:59:09.196571Z","iopub.status.idle":"2024-03-19T08:59:09.207630Z","shell.execute_reply.started":"2024-03-19T08:59:09.196549Z","shell.execute_reply":"2024-03-19T08:59:09.206782Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def flatten_indices(seq_lens, width):\n    flat = []\n    for i, l in enumerate(seq_lens):\n        for j in range(l):\n            flat.append(i * width + j)\n    return flat","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.214251Z","iopub.execute_input":"2024-03-19T08:59:09.214524Z","iopub.status.idle":"2024-03-19T08:59:09.221808Z","shell.execute_reply.started":"2024-03-19T08:59:09.214502Z","shell.execute_reply":"2024-03-19T08:59:09.220857Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def set_cuda(var, cuda):\n    if cuda:\n        return var.cuda()\n    return var","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.223008Z","iopub.execute_input":"2024-03-19T08:59:09.223605Z","iopub.status.idle":"2024-03-19T08:59:09.231366Z","shell.execute_reply.started":"2024-03-19T08:59:09.223580Z","shell.execute_reply":"2024-03-19T08:59:09.230568Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def keep_partial_grad(grad, topk):\n    \"\"\"\n    Keep only the topk rows of grads.\n    \"\"\"\n    assert topk < grad.size(0)\n    grad.data[topk:].zero_()\n    return grad","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.232455Z","iopub.execute_input":"2024-03-19T08:59:09.232716Z","iopub.status.idle":"2024-03-19T08:59:09.241754Z","shell.execute_reply.started":"2024-03-19T08:59:09.232695Z","shell.execute_reply":"2024-03-19T08:59:09.240863Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def save(model, optimizer, opt, filename):\n    params = {\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'config': opt\n    }\n    try:\n        torch.save(params, filename)\n    except BaseException:\n        print(\"[ Warning: model saving failed. ]\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.242949Z","iopub.execute_input":"2024-03-19T08:59:09.243320Z","iopub.status.idle":"2024-03-19T08:59:09.252005Z","shell.execute_reply.started":"2024-03-19T08:59:09.243286Z","shell.execute_reply":"2024-03-19T08:59:09.251208Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def load(model, optimizer, filename):\n    try:\n        dump = torch.load(filename)\n    except BaseException:\n        print(\"[ Fail: model loading failed. ]\")\n    if model is not None:\n        model.load_state_dict(dump['model'])\n    if optimizer is not None:\n        optimizer.load_state_dict(dump['optimizer'])\n    opt = dump['config']\n    return model, optimizer, opt","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.253332Z","iopub.execute_input":"2024-03-19T08:59:09.254010Z","iopub.status.idle":"2024-03-19T08:59:09.267006Z","shell.execute_reply.started":"2024-03-19T08:59:09.253977Z","shell.execute_reply":"2024-03-19T08:59:09.266175Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def load_config(filename):\n    try:\n        dump = torch.load(filename)\n    except BaseException:\n        print(\"[ Fail: model loading failed. ]\")\n    return dump['config']","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.268048Z","iopub.execute_input":"2024-03-19T08:59:09.268620Z","iopub.status.idle":"2024-03-19T08:59:09.282087Z","shell.execute_reply.started":"2024-03-19T08:59:09.268594Z","shell.execute_reply":"2024-03-19T08:59:09.281148Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport pdb\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.283209Z","iopub.execute_input":"2024-03-19T08:59:09.283542Z","iopub.status.idle":"2024-03-19T08:59:09.300418Z","shell.execute_reply.started":"2024-03-19T08:59:09.283511Z","shell.execute_reply":"2024-03-19T08:59:09.299544Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Trainer(object):\n    def __init__(self, opt):\n        raise NotImplementedError\n\n    def update(self, batch):\n        raise NotImplementedError\n\n    def predict(self, batch):\n        raise NotImplementedError\n\n    def update_lr(self, new_lr):  # here should change\n        change_lr(self.optimizer, new_lr)\n\n    def load(self, filename):\n        try:\n            checkpoint = torch.load(filename)\n        except BaseException:\n            print(\"Cannot load model from {}\".format(filename))\n            exit()\n        self.model.load_state_dict(checkpoint['model'])\n        self.opt = checkpoint['config']\n\n    def save(self, filename, epoch):\n        params = {\n            'model': self.model.state_dict(),\n            'config': self.opt,\n        }\n        try:\n            torch.save(params, filename)\n            print(\"model saved to {}\".format(filename))\n        except BaseException:\n            print(\"[Warning: Saving failed... continuing anyway.]\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.301652Z","iopub.execute_input":"2024-03-19T08:59:09.301908Z","iopub.status.idle":"2024-03-19T08:59:09.311031Z","shell.execute_reply.started":"2024-03-19T08:59:09.301886Z","shell.execute_reply":"2024-03-19T08:59:09.310151Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class CDSRTrainer(Trainer):\n    def __init__(self, opt, adj = None, adj_single = None):\n        self.opt = opt\n        if opt[\"model\"] == \"C2DSR\":\n            self.model = C2DSR(opt, adj, adj_single)\n        else:\n            print(\"please select a valid model\")\n            exit(0)\n\n        self.mi_loss = 0\n        self.BCE_criterion = nn.BCEWithLogitsLoss()\n        self.CS_criterion = nn.CrossEntropyLoss(reduction='none')\n        if opt['cuda']:\n            self.model.cuda()\n            self.BCE_criterion.cuda()\n            self.CS_criterion.cuda()\n        self.optimizer = get_optimizer(opt['optim'], self.model.parameters(), opt['lr'])\n\n    def get_dot_score(self, A_embedding, B_embedding):\n        output = (A_embedding * B_embedding).sum(dim=-1)\n        return output\n\n    def unpack_batch_predict(self, batch):\n        if self.opt[\"cuda\"]:\n            inputs = [Variable(b.cuda()) for b in batch]\n            seq = inputs[0]\n            x_seq = inputs[1]\n            y_seq = inputs[2]\n            position = inputs[3]\n            x_position = inputs[4]\n            y_position = inputs[5]\n            X_last = inputs[6]\n            Y_last = inputs[7]\n            XorY = inputs[8]\n            ground_truth = inputs[9]\n            neg_list = inputs[10]\n        else:\n            inputs = [Variable(b) for b in batch]\n            seq = inputs[0]\n            x_seq = inputs[1]\n            y_seq = inputs[2]\n            position = inputs[3]\n            x_position = inputs[4]\n            y_position = inputs[5]\n            X_last = inputs[6]\n            Y_last = inputs[7]\n            XorY = inputs[8]\n            ground_truth = inputs[9]\n            neg_list = inputs[10]\n        return seq, x_seq, y_seq, position, x_position, y_position, X_last, Y_last, XorY, ground_truth, neg_list\n\n    def unpack_batch(self, batch):\n        if self.opt[\"cuda\"]:\n            inputs = [Variable(b.cuda()) for b in batch]\n            seq = inputs[0]\n            x_seq = inputs[1]\n            y_seq = inputs[2]\n            position = inputs[3]\n            x_position = inputs[4]\n            y_position = inputs[5]\n            ground = inputs[6]\n            share_x_ground = inputs[7]\n            share_y_ground = inputs[8]\n            x_ground = inputs[9]\n            y_ground = inputs[10]\n            ground_mask = inputs[11]\n            share_x_ground_mask = inputs[12]\n            share_y_ground_mask = inputs[13]\n            x_ground_mask = inputs[14]\n            y_ground_mask = inputs[15]\n            corru_x = inputs[16]\n            corru_y = inputs[17]\n        else:\n            inputs = [Variable(b) for b in batch]\n            seq = inputs[0]\n            x_seq = inputs[1]\n            y_seq = inputs[2]\n            position = inputs[3]\n            x_position = inputs[4]\n            y_position = inputs[5]\n            ground = inputs[6]\n            share_x_ground = inputs[7]\n            share_y_ground = inputs[8]\n            x_ground = inputs[9]\n            y_ground = inputs[10]\n            ground_mask = inputs[11]\n            share_x_ground_mask = inputs[12]\n            share_y_ground_mask = inputs[13]\n            x_ground_mask = inputs[14]\n            y_ground_mask = inputs[15]\n            corru_x = inputs[16]\n            corru_y = inputs[17]\n        return seq, x_seq, y_seq, position, x_position, y_position, ground, share_x_ground, share_y_ground, x_ground, y_ground, ground_mask, share_x_ground_mask, share_y_ground_mask, x_ground_mask, y_ground_mask, corru_x, corru_y\n\n#     def HingeLoss(self, pos, neg):\n#         gamma = torch.tensor(self.opt[\"margin\"])\n#         if self.opt[\"cuda\"]:\n#             gamma = gamma.cuda()\n#         return F.relu(gamma - pos + neg).mean()\n    \n    def HingeLoss(self, pos, neg):\n        pos_prob = torch.sigmoid(pos)\n        neg_prob = 1 - torch.sigmoid(neg)\n\n        logits = torch.cat((pos_prob, neg_prob), dim=1)\n        labels = torch.ones_like(pos)  \n\n        if self.opt[\"cuda\"]:\n            criterion = F.cross_entropy(reduction='mean').cuda()\n\n        return criterion(logits, labels)\n\n\n    def train_batch(self, batch):\n        self.model.train()\n        self.optimizer.zero_grad()\n        self.model.graph_convolution()\n\n        seq, x_seq, y_seq, position, x_position, y_position, ground, share_x_ground, share_y_ground, x_ground, y_ground, ground_mask, share_x_ground_mask, share_y_ground_mask, x_ground_mask, y_ground_mask, corru_x, corru_y = self.unpack_batch(batch)\n        seqs_fea, x_seqs_fea, y_seqs_fea = self.model(seq, x_seq, y_seq, position, x_position, y_position)\n\n        corru_x_fea = self.model.false_forward(corru_x, position)\n        corru_y_fea = self.model.false_forward(corru_y, position)\n\n        x_mask = x_ground_mask.float().sum(-1).unsqueeze(-1).repeat(1,x_ground_mask.size(-1))\n        x_mask = 1 / x_mask\n        x_mask = x_ground_mask * x_mask # for mean\n        x_mask = x_mask.unsqueeze(-1).repeat(1,1,seqs_fea.size(-1))\n        r_x_fea = (x_seqs_fea * x_mask).sum(1)\n\n        y_mask = y_ground_mask.float().sum(-1).unsqueeze(-1).repeat(1, y_ground_mask.size(-1))\n        y_mask = 1 / y_mask\n        y_mask = y_ground_mask * y_mask # for mean\n        y_mask = y_mask.unsqueeze(-1).repeat(1,1,seqs_fea.size(-1))\n        r_y_fea = (y_seqs_fea * y_mask).sum(1)\n\n\n        real_x_fea = (seqs_fea * x_mask).sum(1)\n        real_y_fea = (seqs_fea * y_mask).sum(1)\n        x_false_fea = (corru_x_fea * x_mask).sum(1)\n        y_false_fea = (corru_y_fea * y_mask).sum(1)\n\n\n        real_x_score = self.model.D_X(r_x_fea, real_y_fea) # the cross-domain infomax\n        false_x_score = self.model.D_X(r_x_fea, y_false_fea)\n\n        real_y_score = self.model.D_Y(r_y_fea, real_x_fea)\n        false_y_score = self.model.D_Y(r_y_fea, x_false_fea)\n\n        pos_label = torch.ones_like(real_x_score).cuda()\n        neg_label = torch.zeros_like(false_x_score).cuda()\n        x_mi_real = self.BCE_criterion(real_x_score, pos_label)\n        x_mi_false = self.BCE_criterion(false_x_score, neg_label)\n        x_mi_loss = x_mi_real + x_mi_false\n\n        y_mi_real = self.BCE_criterion(real_y_score, pos_label)\n        y_mi_false = self.BCE_criterion(false_y_score, neg_label)\n        y_mi_loss = y_mi_real + y_mi_false\n\n        used = 10\n        ground = ground[:,-used:]\n        ground_mask = ground_mask[:, -used:]\n        share_x_ground = share_x_ground[:, -used:]\n        share_x_ground_mask = share_x_ground_mask[:, -used:]\n        share_y_ground = share_y_ground[:, -used:]\n        share_y_ground_mask = share_y_ground_mask[:, -used:]\n        x_ground = x_ground[:, -used:]\n        x_ground_mask = x_ground_mask[:, -used:]\n        y_ground = y_ground[:, -used:]\n        y_ground_mask = y_ground_mask[:, -used:]\n\n\n        share_x_result =  self.model.lin_X(seqs_fea[:,-used:]) # b * seq * X_num\n        share_y_result = self.model.lin_Y(seqs_fea[:, -used:])  # b * seq * Y_num\n        share_pad_result = self.model.lin_PAD(seqs_fea[:, -used:])  # b * seq * 1\n        share_trans_x_result = torch.cat((share_x_result, share_pad_result), dim=-1)\n        share_trans_y_result = torch.cat((share_y_result, share_pad_result), dim=-1)\n\n\n        specific_x_result = self.model.lin_X(seqs_fea[:,-used:] + x_seqs_fea[:, -used:])  # b * seq * X_num\n        specific_x_pad_result = self.model.lin_PAD(x_seqs_fea[:, -used:])  # b * seq * 1\n        specific_x_result = torch.cat((specific_x_result, specific_x_pad_result), dim=-1)\n\n        specific_y_result = self.model.lin_Y(seqs_fea[:,-used:] + y_seqs_fea[:, -used:])  # b * seq * Y_num\n        specific_y_pad_result = self.model.lin_PAD(y_seqs_fea[:, -used:])  # b * seq * 1\n        specific_y_result = torch.cat((specific_y_result, specific_y_pad_result), dim=-1)\n\n        x_share_loss = self.CS_criterion(\n            share_trans_x_result.reshape(-1, self.opt[\"source_item_num\"] + 1),\n            share_x_ground.reshape(-1))  # b * seq\n        y_share_loss = self.CS_criterion(\n            share_trans_y_result.reshape(-1, self.opt[\"target_item_num\"] + 1),\n            share_y_ground.reshape(-1))  # b * seq\n        x_loss = self.CS_criterion(\n            specific_x_result.reshape(-1, self.opt[\"source_item_num\"] + 1),\n            x_ground.reshape(-1))  # b * seq\n        y_loss = self.CS_criterion(\n            specific_y_result.reshape(-1, self.opt[\"target_item_num\"] + 1),\n            y_ground.reshape(-1))  # b * seq\n\n        x_share_loss = (x_share_loss * (share_x_ground_mask.reshape(-1))).mean()\n        y_share_loss = (y_share_loss * (share_y_ground_mask.reshape(-1))).mean()\n        x_loss = (x_loss * (x_ground_mask.reshape(-1))).mean()\n        y_loss = (y_loss * (y_ground_mask.reshape(-1))).mean()\n\n        loss = self.opt[\"lambda\"]*(x_share_loss + y_share_loss + x_loss + y_loss) + (1 - self.opt[\"lambda\"]) * (x_mi_loss + y_mi_loss)\n\n        self.mi_loss += (1 - self.opt[\"lambda\"]) * (x_mi_loss.item() + y_mi_loss.item())\n        loss.backward()\n        self.optimizer.step()\n\n        return loss.item()\n\n    def test_batch(self, batch):\n        seq, x_seq, y_seq, position, x_position, y_position, X_last, Y_last, XorY, ground_truth, neg_list = self.unpack_batch_predict(batch)\n        seqs_fea, x_seqs_fea, y_seqs_fea = self.model(seq, x_seq, y_seq, position, x_position, y_position)\n\n        X_pred = []\n        Y_pred = []\n        for id, fea in enumerate(seqs_fea): # b * s * f\n            if XorY[id] == 0:\n                share_fea = seqs_fea[id, -1]\n                specific_fea = x_seqs_fea[id, X_last[id]]\n                X_score = self.model.lin_X(share_fea + specific_fea).squeeze(0)\n                cur = X_score[ground_truth[id]]\n                score_larger = (X_score[neg_list[id]] > (cur + 0.00001)).data.cpu().numpy()\n                true_item_rank = np.sum(score_larger) + 1\n                X_pred.append(true_item_rank)\n\n            else :\n                share_fea = seqs_fea[id, -1]\n                specific_fea = y_seqs_fea[id, Y_last[id]]\n                Y_score = self.model.lin_Y(share_fea + specific_fea).squeeze(0)\n                cur = Y_score[ground_truth[id]]\n                score_larger = (Y_score[neg_list[id]] > (cur + 0.00001)).data.cpu().numpy()\n                true_item_rank = np.sum(score_larger) + 1\n                Y_pred.append(true_item_rank)\n\n        return X_pred, Y_pred","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.312251Z","iopub.execute_input":"2024-03-19T08:59:09.312899Z","iopub.status.idle":"2024-03-19T08:59:09.361400Z","shell.execute_reply.started":"2024-03-19T08:59:09.312876Z","shell.execute_reply":"2024-03-19T08:59:09.360506Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Train_Rec","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nfrom datetime import datetime\nimport time\nimport numpy as np\nimport random\nimport argparse\nfrom shutil import copyfile\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport json\nimport codecs\nimport tqdm\nimport pdb","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.362429Z","iopub.execute_input":"2024-03-19T08:59:09.362742Z","iopub.status.idle":"2024-03-19T08:59:09.378308Z","shell.execute_reply.started":"2024-03-19T08:59:09.362709Z","shell.execute_reply":"2024-03-19T08:59:09.377400Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\n\nparser.add_argument('-f')\n# dataset part\nparser.add_argument('--data_dir', type=str, default='Entertainment-Education', help='Food-Kitchen, Movie-Book')\n\n# model part\nparser.add_argument('--model', type=str, default=\"C2DSR\", help='model name')\nparser.add_argument('--hidden_units', type=int, default=256, help='lantent dim.')\nparser.add_argument('--num_blocks', type=int, default=2, help='lantent dim.')\nparser.add_argument('--num_heads', type=int, default=1, help='lantent dim.')\nparser.add_argument('--GNN', type=int, default=1, help='GNN depth.')\nparser.add_argument('--dropout', type=float, default=0.2, help='dropout rate.')\nparser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adagrad',\n                    help='Optimizer: sgd, adagrad, adam or adamax.')\nparser.add_argument('--lr', type=float, default=0.001, help='Applies to sgd and adagrad.')\nparser.add_argument('--lr_decay', type=float, default=1, help='Learning rate decay rate.')\nparser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters).')\nparser.add_argument('--decay_epoch', type=int, default=5, help='Decay learning rate after this epoch.')\nparser.add_argument('--max_grad_norm', type=float, default=5.0, help='Gradient clipping.')\nparser.add_argument('--leakey', type=float, default=0.1)\nparser.add_argument('--maxlen', type=int, default=15)\nparser.add_argument('--cpu', action='store_true', help='Ignore CUDA.')\nparser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\nparser.add_argument('--lambda', type=float, default=0.7)\n\n# train part\nparser.add_argument('--num_epoch', type=int, default=100, help='Number of total training epochs.')\nparser.add_argument('--batch_size', type=int, default=256, help='Training batch size.')\nparser.add_argument('--log_step', type=int, default=200, help='Print log every k steps.')\nparser.add_argument('--log', type=str, default='logs.txt', help='Write training log to file.')\nparser.add_argument('--save_epoch', type=int, default=100, help='Save model checkpoints every k epochs.')\nparser.add_argument('--save_dir', type=str, default='./saved_models', help='Root dir for saving models.')\nparser.add_argument('--id', type=str, default='00', help='Model ID under which to save models.')\nparser.add_argument('--seed', type=int, default=2040)\nparser.add_argument('--load', dest='load', action='store_true', default=False,  help='Load pretrained model.')\nparser.add_argument('--model_file', type=str, help='Filename of the pretrained model.')\nparser.add_argument('--info', type=str, default='', help='Optional info for the experiment.')\nparser.add_argument('--undebug', action='store_false', default=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.379608Z","iopub.execute_input":"2024-03-19T08:59:09.379939Z","iopub.status.idle":"2024-03-19T08:59:09.455976Z","shell.execute_reply.started":"2024-03-19T08:59:09.379901Z","shell.execute_reply":"2024-03-19T08:59:09.454858Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"_StoreFalseAction(option_strings=['--undebug'], dest='undebug', nargs=0, const=False, default=True, type=None, choices=None, required=False, help=None, metavar=None)"},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed=1111):\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.457588Z","iopub.execute_input":"2024-03-19T08:59:09.458351Z","iopub.status.idle":"2024-03-19T08:59:09.467786Z","shell.execute_reply.started":"2024-03-19T08:59:09.458270Z","shell.execute_reply":"2024-03-19T08:59:09.466932Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"args = parser.parse_args()\nif args.cpu:\n    args.cuda = False\nelif args.cuda:\n    torch.cuda.manual_seed(args.seed)\ninit_time = time.time()\n# make opt\nopt = vars(args)\n\nseed_everything(opt[\"seed\"])\n\nmodel_id = opt['id'] if len(opt['id']) > 1 else '0' + opt['id']\nmodel_save_dir = opt['save_dir'] + '/' + model_id\nopt['model_save_dir'] = model_save_dir\nensure_dir(model_save_dir, verbose=True)\n# save config\nsave_config(opt, model_save_dir + '/config.json', verbose=True)\nfile_logger = FileLogger(model_save_dir + '/' + opt['log'],\n                                header=\"# epoch\\ttrain_loss\\tdev_loss\\tdev_score\\tbest_dev_score\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.469183Z","iopub.execute_input":"2024-03-19T08:59:09.469941Z","iopub.status.idle":"2024-03-19T08:59:09.484781Z","shell.execute_reply.started":"2024-03-19T08:59:09.469909Z","shell.execute_reply":"2024-03-19T08:59:09.483746Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Directory ./saved_models/00 do not exist; creating...\nConfig saved to file ./saved_models/00/config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# print model info\nprint_config(opt)\n\nif opt[\"undebug\"]:\n    pass\n    # opt[\"cuda\"] = False\n    # opt[\"cpu\"] = True\n\nprint(\"Loading data from {} with batch size {}...\".format(opt['data_dir'], opt['batch_size']))\ntrain_batch = DataLoader(opt['data_dir'], opt['batch_size'], opt, evaluation = -1)\nvalid_batch = DataLoader(opt['data_dir'], opt[\"batch_size\"], opt, evaluation = 2)\ntest_batch = DataLoader(opt['data_dir'], opt[\"batch_size\"], opt, evaluation = 1)\nprint(\"Data loading done!\")\n\nopt[\"itemnum\"] = opt[\"source_item_num\"] + opt[\"target_item_num\"] + 1","metadata":{"execution":{"iopub.status.busy":"2024-03-19T08:59:09.485995Z","iopub.execute_input":"2024-03-19T08:59:09.486338Z","iopub.status.idle":"2024-03-19T09:00:18.375712Z","shell.execute_reply.started":"2024-03-19T08:59:09.486309Z","shell.execute_reply":"2024-03-19T09:00:18.374593Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\nRunning with the following configs:\n\tf : /root/.local/share/jupyter/runtime/kernel-e9726718-a74a-4680-b407-7667c7c071ff.json\n\tdata_dir : Entertainment-Education\n\tmodel : C2DSR\n\thidden_units : 256\n\tnum_blocks : 2\n\tnum_heads : 1\n\tGNN : 1\n\tdropout : 0.2\n\toptim : adagrad\n\tlr : 0.001\n\tlr_decay : 1\n\tweight_decay : 0.0005\n\tdecay_epoch : 5\n\tmax_grad_norm : 5.0\n\tleakey : 0.1\n\tmaxlen : 15\n\tcpu : False\n\tcuda : True\n\tlambda : 0.7\n\tnum_epoch : 100\n\tbatch_size : 256\n\tlog_step : 200\n\tlog : logs.txt\n\tsave_epoch : 100\n\tsave_dir : ./saved_models\n\tid : 00\n\tseed : 2040\n\tload : False\n\tmodel_file : None\n\tinfo : \n\tundebug : True\n\tmodel_save_dir : ./saved_models/00\n\n\nLoading data from Entertainment-Education with batch size 256...\npass sequence x\nData loading done!\n","output_type":"stream"}]},{"cell_type":"code","source":"filename = opt[\"data_dir\"]\ntrain_data = \"/kaggle/input/cross-domain-recommendation/dataset/\" + filename + \"/traindata_new.txt\"\nG = GraphMaker(opt, train_data)\nadj, adj_single = G.adj, G.adj_single\nprint(\"graph loaded!\")\n\nif opt[\"cuda\"]:\n    adj = adj.cuda()\n    adj_single = adj_single.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:00:18.377229Z","iopub.execute_input":"2024-03-19T09:00:18.377586Z","iopub.status.idle":"2024-03-19T09:00:48.876071Z","shell.execute_reply.started":"2024-03-19T09:00:18.377557Z","shell.execute_reply":"2024-03-19T09:00:48.874771Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2768315390.py:4: RuntimeWarning: divide by zero encountered in power\n  r_inv = np.power(rowsum, -1).flatten()\n/tmp/ipykernel_35/3650411315.py:8: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:605.)\n  return torch.sparse.FloatTensor(indices, values, shape)\n","output_type":"stream"},{"name":"stdout","text":"real graph loaded!\ngraph loaded!\n","output_type":"stream"}]},{"cell_type":"code","source":"# model\nif not opt['load']:\n    trainer = CDSRTrainer(opt, adj, adj_single)\nelse:\n    exit(0)\n\nglobal_step = 0\ncurrent_lr = opt[\"lr\"]\nformat_str = '{}: step {}/{} (epoch {}/{}), loss = {:.6f} ({:.3f} sec/epoch), lr: {:.6f}'\nnum_batch = len(train_batch)\nmax_steps = opt['num_epoch'] * num_batch\n\nprint(\"Start training:\")\n\nbegin_time = time.time()\nX_dev_score_history=[0]\nY_dev_score_history=[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:00:48.877624Z","iopub.execute_input":"2024-03-19T09:00:48.877946Z","iopub.status.idle":"2024-03-19T09:00:52.827533Z","shell.execute_reply.started":"2024-03-19T09:00:48.877918Z","shell.execute_reply":"2024-03-19T09:00:52.826437Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Start training:\n","output_type":"stream"}]},{"cell_type":"code","source":"# start training\nfor epoch in range(1, opt['num_epoch'] + 1):\n    train_loss = 0\n    epoch_start_time = time.time()\n    trainer.mi_loss = 0\n    for batch in train_batch:\n        global_step += 1\n        loss = trainer.train_batch(batch)\n        train_loss += loss\n\n    duration = time.time() - epoch_start_time\n    print(format_str.format(datetime.now(), global_step, max_steps, epoch, \\\n                                    opt['num_epoch'], train_loss/num_batch, duration, current_lr))\n    print(\"mi:\", trainer.mi_loss/num_batch)\n\n    if epoch % 5:\n        continue\n\n    # eval model\n    print(\"Evaluating on dev set...\")\n\n    trainer.model.eval()\n    trainer.model.graph_convolution()\n\n\n    def cal_test_score(predictions):\n        MRR=0.0\n        HR_1 = 0.0\n        HR_5 = 0.0\n        HR_10 = 0.0\n        NDCG_5 = 0.0\n        NDCG_10 = 0.0\n        valid_entity = 0.0\n        # pdb.set_trace()\n        for pred in predictions:\n            valid_entity += 1\n            MRR += 1 / pred\n            if pred <= 1:\n                HR_1 += 1\n            if pred <= 5:\n                NDCG_5 += 1 / np.log2(pred + 1)\n                HR_5 += 1\n            if pred <= 10:\n                NDCG_10 += 1 / np.log2(pred + 1)\n                HR_10 += 1\n            if valid_entity % 100 == 0:\n                print('.', end='')\n        return MRR/valid_entity, NDCG_5 / valid_entity, NDCG_10 / valid_entity, HR_1 / valid_entity, HR_5 / valid_entity, HR_10 / valid_entity\n\n    def get_evaluation_result(evaluation_batch):\n        X_pred = []\n        Y_pred = []\n        for i, batch in enumerate(evaluation_batch):\n            X_predictions, Y_predictions = trainer.test_batch(batch)\n            X_pred = X_pred + X_predictions\n            Y_pred = Y_pred + Y_predictions\n\n        return X_pred, Y_pred\n\n\n    val_X_pred, val_Y_pred = get_evaluation_result(valid_batch)\n    val_X_MRR, val_X_NDCG_5, val_X_NDCG_10, val_X_HR_1, val_X_HR_5, val_X_HR_10 = cal_test_score(val_X_pred)\n    val_Y_MRR, val_Y_NDCG_5, val_Y_NDCG_10, val_Y_HR_1, val_Y_HR_5, val_Y_HR_10 = cal_test_score(val_Y_pred)\n\n    print(\"\")\n    print('val epoch:%d, time: %f(s), X (MRR: %.4f, NDCG@10: %.4f, HR@10: %.4f), Y (MRR: %.4f, NDCG@10: %.4f, HR@10: %.4f)'\n          % (epoch, time.time() - begin_time, val_X_MRR, val_X_NDCG_10, val_X_HR_10, val_Y_MRR, val_Y_NDCG_10, val_Y_HR_10))\n\n    if val_X_MRR > max(X_dev_score_history) or val_Y_MRR > max(Y_dev_score_history):\n        test_X_pred, test_Y_pred = get_evaluation_result(test_batch)\n        test_X_MRR, test_X_NDCG_5, test_X_NDCG_10, test_X_HR_1, test_X_HR_5, test_X_HR_10 = cal_test_score(test_X_pred)\n        test_Y_MRR, test_Y_NDCG_5, test_Y_NDCG_10, test_Y_HR_1, test_Y_HR_5, test_Y_HR_10 = cal_test_score(test_Y_pred)\n\n        print(\"\")\n        if val_X_MRR > max(X_dev_score_history):\n            print(\"X best!\")\n            print([test_X_MRR, test_X_NDCG_5, test_X_NDCG_10, test_X_HR_1, test_X_HR_5, test_X_HR_10])\n\n        if val_Y_MRR > max(Y_dev_score_history):\n            print(\"Y best!\")\n            print([test_Y_MRR, test_Y_NDCG_5, test_Y_NDCG_10, test_Y_HR_1, test_Y_HR_5, test_Y_HR_10])\n\n    X_dev_score_history.append(val_X_MRR)\n    Y_dev_score_history.append(val_Y_MRR)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:00:52.829266Z","iopub.execute_input":"2024-03-19T09:00:52.829747Z","iopub.status.idle":"2024-03-19T13:53:30.431998Z","shell.execute_reply.started":"2024-03-19T09:00:52.829717Z","shell.execute_reply":"2024-03-19T13:53:30.431056Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2765941852.py:77: UserWarning: This overload of addcmul_ is deprecated:\n\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\nConsider using one of the following signatures instead:\n\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/python_arg_parser.cpp:1519.)\n  state['sum'].addcmul_(1, grad, grad)\n","output_type":"stream"},{"name":"stdout","text":"2024-03-19 09:03:45.003875: step 472/47200 (epoch 1/100), loss = 13.263966 (172.154 sec/epoch), lr: 0.001000\nmi: 0.7943236586148454\n2024-03-19 09:06:40.057514: step 944/47200 (epoch 2/100), loss = 12.950979 (175.053 sec/epoch), lr: 0.001000\nmi: 0.7259552791714668\n2024-03-19 09:09:34.918771: step 1416/47200 (epoch 3/100), loss = 12.337447 (174.861 sec/epoch), lr: 0.001000\nmi: 0.6789788725770127\n2024-03-19 09:12:29.949845: step 1888/47200 (epoch 4/100), loss = 11.514235 (175.031 sec/epoch), lr: 0.001000\nmi: 0.6589505904054235\n2024-03-19 09:15:24.885353: step 2360/47200 (epoch 5/100), loss = 11.028319 (174.935 sec/epoch), lr: 0.001000\nmi: 0.6380613603202969\nEvaluating on dev set...\n.....................................................................\nval epoch:5, time: 876.772353(s), X (MRR: 0.2182, NDCG@10: 0.2686, HR@10: 0.4597), Y (MRR: 0.2874, NDCG@10: 0.3236, HR@10: 0.4559)\n...................................................................\nX best!\n[0.22963391819446038, 0.23961635964620592, 0.27967826264804574, 0.12798216276477145, 0.3462653288740245, 0.46978818283166107]\nY best!\n[0.2904998192232153, 0.3093078362825755, 0.3271100430071817, 0.19782608695652174, 0.4078260869565217, 0.4617391304347826]\n2024-03-19 09:18:29.137686: step 2832/47200 (epoch 6/100), loss = 10.739976 (175.009 sec/epoch), lr: 0.001000\nmi: 0.6133472433155877\n2024-03-19 09:21:24.173612: step 3304/47200 (epoch 7/100), loss = 10.535738 (175.036 sec/epoch), lr: 0.001000\nmi: 0.5902875847356802\n2024-03-19 09:24:19.152891: step 3776/47200 (epoch 8/100), loss = 10.383253 (174.979 sec/epoch), lr: 0.001000\nmi: 0.5714457771156801\n2024-03-19 09:27:14.347266: step 4248/47200 (epoch 9/100), loss = 10.258435 (175.194 sec/epoch), lr: 0.001000\nmi: 0.5535164630261521\n2024-03-19 09:30:08.960282: step 4720/47200 (epoch 10/100), loss = 10.155729 (174.613 sec/epoch), lr: 0.001000\nmi: 0.5384053497370017\nEvaluating on dev set...\n.....................................................................\nval epoch:10, time: 1761.264094(s), X (MRR: 0.2456, NDCG@10: 0.2912, HR@10: 0.4829), Y (MRR: 0.3184, NDCG@10: 0.3640, HR@10: 0.5379)\n...................................................................\nX best!\n[0.25660735934026185, 0.2620652556036373, 0.3045662948744174, 0.14849498327759197, 0.3712374581939799, 0.5025641025641026]\nY best!\n[0.3178447713646741, 0.33142974887122345, 0.3652096758336403, 0.21304347826086956, 0.43956521739130433, 0.5430434782608695]\n2024-03-19 09:33:14.311322: step 5192/47200 (epoch 11/100), loss = 10.066868 (175.260 sec/epoch), lr: 0.001000\nmi: 0.5237810476099031\n2024-03-19 09:36:08.868281: step 5664/47200 (epoch 12/100), loss = 9.991755 (174.557 sec/epoch), lr: 0.001000\nmi: 0.5120353307638127\n2024-03-19 09:39:03.848002: step 6136/47200 (epoch 13/100), loss = 9.925378 (174.980 sec/epoch), lr: 0.001000\nmi: 0.5010659710961886\n2024-03-19 09:41:58.730268: step 6608/47200 (epoch 14/100), loss = 9.865020 (174.882 sec/epoch), lr: 0.001000\nmi: 0.4903769964888946\n2024-03-19 09:44:53.376045: step 7080/47200 (epoch 15/100), loss = 9.811363 (174.646 sec/epoch), lr: 0.001000\nmi: 0.48166685067748655\nEvaluating on dev set...\n.....................................................................\nval epoch:15, time: 2645.240824(s), X (MRR: 0.2622, NDCG@10: 0.3040, HR@10: 0.4862), Y (MRR: 0.3345, NDCG@10: 0.3759, HR@10: 0.5433)\n...................................................................\nX best!\n[0.2760734544836947, 0.28114022906984937, 0.32056481938702164, 0.16878483835005575, 0.3875139353400223, 0.5094760312151616]\nY best!\n[0.3364082800515686, 0.3464518429592997, 0.378304992334857, 0.23478260869565218, 0.44869565217391305, 0.5456521739130434]\n2024-03-19 09:47:56.266454: step 7552/47200 (epoch 16/100), loss = 9.762609 (173.634 sec/epoch), lr: 0.001000\nmi: 0.47289109594993683\n2024-03-19 09:50:49.882433: step 8024/47200 (epoch 17/100), loss = 9.718537 (173.616 sec/epoch), lr: 0.001000\nmi: 0.4660614515007551\n2024-03-19 09:53:43.552974: step 8496/47200 (epoch 18/100), loss = 9.675679 (173.670 sec/epoch), lr: 0.001000\nmi: 0.45741077227107596\n2024-03-19 09:56:36.975171: step 8968/47200 (epoch 19/100), loss = 9.635970 (173.422 sec/epoch), lr: 0.001000\nmi: 0.4507896156255475\n2024-03-19 09:59:30.333612: step 9440/47200 (epoch 20/100), loss = 9.599839 (173.358 sec/epoch), lr: 0.001000\nmi: 0.44474970159136623\nEvaluating on dev set...\n.....................................................................\nval epoch:20, time: 3522.079321(s), X (MRR: 0.2757, NDCG@10: 0.3173, HR@10: 0.4975), Y (MRR: 0.3425, NDCG@10: 0.3814, HR@10: 0.5441)\n...................................................................\nX best!\n[0.2875325190203114, 0.2929654090990776, 0.3313437609761204, 0.17881828316610926, 0.39933110367892977, 0.5177257525083612]\nY best!\n[0.3466708793837414, 0.3575815753447859, 0.38626573072670867, 0.24608695652173912, 0.46043478260869564, 0.5491304347826087]\n2024-03-19 10:02:32.666673: step 9912/47200 (epoch 21/100), loss = 9.564447 (173.330 sec/epoch), lr: 0.001000\nmi: 0.43767135128126305\n2024-03-19 10:05:26.160172: step 10384/47200 (epoch 22/100), loss = 9.531795 (173.493 sec/epoch), lr: 0.001000\nmi: 0.43145731581469726\n2024-03-19 10:08:19.577733: step 10856/47200 (epoch 23/100), loss = 9.502128 (173.417 sec/epoch), lr: 0.001000\nmi: 0.4266451714023694\n2024-03-19 10:11:12.923831: step 11328/47200 (epoch 24/100), loss = 9.471851 (173.346 sec/epoch), lr: 0.001000\nmi: 0.42083265387405794\n2024-03-19 10:14:06.334252: step 11800/47200 (epoch 25/100), loss = 9.444935 (173.410 sec/epoch), lr: 0.001000\nmi: 0.41634660318998984\nEvaluating on dev set...\n.....................................................................\nval epoch:25, time: 4398.050626(s), X (MRR: 0.2852, NDCG@10: 0.3266, HR@10: 0.5052), Y (MRR: 0.3481, NDCG@10: 0.3847, HR@10: 0.5420)\n...................................................................\nX best!\n[0.2956031224561997, 0.3023076768226698, 0.34004710270080535, 0.1841694537346711, 0.4107023411371237, 0.5270903010033445]\nY best!\n[0.3562362388167311, 0.36513725130325403, 0.3938455976561091, 0.2565217391304348, 0.46260869565217394, 0.551304347826087]\n2024-03-19 10:17:08.875518: step 12272/47200 (epoch 26/100), loss = 9.418827 (173.553 sec/epoch), lr: 0.001000\nmi: 0.4110126529709765\n2024-03-19 10:20:02.389017: step 12744/47200 (epoch 27/100), loss = 9.394827 (173.513 sec/epoch), lr: 0.001000\nmi: 0.4060398416246398\n2024-03-19 10:22:55.891566: step 13216/47200 (epoch 28/100), loss = 9.371218 (173.502 sec/epoch), lr: 0.001000\nmi: 0.4020490022281468\n2024-03-19 10:25:49.369398: step 13688/47200 (epoch 29/100), loss = 9.348408 (173.478 sec/epoch), lr: 0.001000\nmi: 0.39729429076788775\n2024-03-19 10:28:42.891234: step 14160/47200 (epoch 30/100), loss = 9.327293 (173.522 sec/epoch), lr: 0.001000\nmi: 0.39346891381477916\nEvaluating on dev set...\n.....................................................................\nval epoch:30, time: 5274.618246(s), X (MRR: 0.2924, NDCG@10: 0.3337, HR@10: 0.5105), Y (MRR: 0.3559, NDCG@10: 0.3921, HR@10: 0.5478)\n...................................................................\nX best!\n[0.3038007367409394, 0.31200291477845693, 0.34776159657934397, 0.19331103678929765, 0.42207357859531774, 0.5324414715719064]\nY best!\n[0.364074445244227, 0.37248422001424647, 0.3992936200483499, 0.26521739130434785, 0.4673913043478261, 0.55]\n2024-03-19 10:31:45.513257: step 14632/47200 (epoch 31/100), loss = 9.306702 (173.540 sec/epoch), lr: 0.001000\nmi: 0.38976302787156386\n2024-03-19 10:34:38.985137: step 15104/47200 (epoch 32/100), loss = 9.287352 (173.472 sec/epoch), lr: 0.001000\nmi: 0.38536017412098794\n2024-03-19 10:37:32.449693: step 15576/47200 (epoch 33/100), loss = 9.266531 (173.464 sec/epoch), lr: 0.001000\nmi: 0.381185815748522\n2024-03-19 10:40:25.989545: step 16048/47200 (epoch 34/100), loss = 9.248084 (173.540 sec/epoch), lr: 0.001000\nmi: 0.37741515599191205\n2024-03-19 10:43:19.444115: step 16520/47200 (epoch 35/100), loss = 9.231104 (173.454 sec/epoch), lr: 0.001000\nmi: 0.37462064044202775\nEvaluating on dev set...\n.....................................................................\nval epoch:35, time: 6151.289312(s), X (MRR: 0.2983, NDCG@10: 0.3396, HR@10: 0.5156), Y (MRR: 0.3618, NDCG@10: 0.3960, HR@10: 0.5462)\n...................................................................\nX best!\n[0.30931911462076483, 0.31824895058763475, 0.35347642562893855, 0.19888517279821627, 0.42920847268673357, 0.5382385730211817]\nY best!\n[0.3690502649002914, 0.37831957166922925, 0.40451638852317284, 0.27043478260869563, 0.4743478260869565, 0.5552173913043478]\n2024-03-19 10:46:22.111743: step 16992/47200 (epoch 36/100), loss = 9.212602 (173.464 sec/epoch), lr: 0.001000\nmi: 0.3708761828556911\n2024-03-19 10:49:15.555681: step 17464/47200 (epoch 37/100), loss = 9.194896 (173.444 sec/epoch), lr: 0.001000\nmi: 0.3673851211129104\n2024-03-19 10:52:09.102364: step 17936/47200 (epoch 38/100), loss = 9.177454 (173.547 sec/epoch), lr: 0.001000\nmi: 0.3641011978862651\n2024-03-19 10:55:02.665464: step 18408/47200 (epoch 39/100), loss = 9.162187 (173.563 sec/epoch), lr: 0.001000\nmi: 0.361539881127113\n2024-03-19 10:57:56.170958: step 18880/47200 (epoch 40/100), loss = 9.146228 (173.505 sec/epoch), lr: 0.001000\nmi: 0.35800320684783526\nEvaluating on dev set...\n.....................................................................\nval epoch:40, time: 7027.911564(s), X (MRR: 0.3040, NDCG@10: 0.3462, HR@10: 0.5235), Y (MRR: 0.3630, NDCG@10: 0.3966, HR@10: 0.5449)\n...................................................................\nX best!\n[0.3148481788827868, 0.3242977213698326, 0.3580559543402869, 0.20535117056856186, 0.4354515050167224, 0.5395763656633222]\nY best!\n[0.37545499781952757, 0.38451623931077883, 0.4111732930313287, 0.2773913043478261, 0.47956521739130437, 0.5617391304347826]\n2024-03-19 11:00:58.757914: step 19352/47200 (epoch 41/100), loss = 9.129341 (173.487 sec/epoch), lr: 0.001000\nmi: 0.35472183844421873\n2024-03-19 11:03:52.271370: step 19824/47200 (epoch 42/100), loss = 9.114204 (173.513 sec/epoch), lr: 0.001000\nmi: 0.3517318544309526\n2024-03-19 11:06:45.827168: step 20296/47200 (epoch 43/100), loss = 9.096671 (173.556 sec/epoch), lr: 0.001000\nmi: 0.3474412506351529\n2024-03-19 11:09:39.633152: step 20768/47200 (epoch 44/100), loss = 9.082472 (173.806 sec/epoch), lr: 0.001000\nmi: 0.3456765175433988\n2024-03-19 11:12:33.188713: step 21240/47200 (epoch 45/100), loss = 9.066798 (173.555 sec/epoch), lr: 0.001000\nmi: 0.3416171465700461\nEvaluating on dev set...\n.....................................................................\nval epoch:45, time: 7904.971617(s), X (MRR: 0.3090, NDCG@10: 0.3513, HR@10: 0.5282), Y (MRR: 0.3677, NDCG@10: 0.4016, HR@10: 0.5499)\n...................................................................\nX best!\n[0.31903272522860765, 0.3292436636292737, 0.3623900405579667, 0.20713489409141583, 0.4414715719063545, 0.5435897435897435]\nY best!\n[0.3813336083168383, 0.39153046123702806, 0.41578496281405786, 0.28347826086956524, 0.48782608695652174, 0.5621739130434783]\n2024-03-19 11:15:35.760806: step 21712/47200 (epoch 46/100), loss = 9.052535 (173.458 sec/epoch), lr: 0.001000\nmi: 0.3396209250125339\n2024-03-19 11:18:29.158252: step 22184/47200 (epoch 47/100), loss = 9.039792 (173.397 sec/epoch), lr: 0.001000\nmi: 0.33712094260726927\n2024-03-19 11:21:22.561531: step 22656/47200 (epoch 48/100), loss = 9.024785 (173.403 sec/epoch), lr: 0.001000\nmi: 0.33304565461762886\n2024-03-19 11:24:15.944856: step 23128/47200 (epoch 49/100), loss = 9.010757 (173.383 sec/epoch), lr: 0.001000\nmi: 0.3306753534192251\n2024-03-19 11:27:09.310670: step 23600/47200 (epoch 50/100), loss = 8.996638 (173.366 sec/epoch), lr: 0.001000\nmi: 0.3276053141423708\nEvaluating on dev set...\n.....................................................................\nval epoch:50, time: 8781.078883(s), X (MRR: 0.3133, NDCG@10: 0.3556, HR@10: 0.5326), Y (MRR: 0.3694, NDCG@10: 0.4035, HR@10: 0.5520)\n...................................................................\nX best!\n[0.3222868329680151, 0.3326105821423226, 0.3662112139066328, 0.20958751393534003, 0.44503901895206244, 0.5487179487179488]\nY best!\n[0.3845480861024632, 0.39542625747646337, 0.41942878328844846, 0.28608695652173916, 0.4930434782608696, 0.5669565217391305]\n2024-03-19 11:30:11.602633: step 24072/47200 (epoch 51/100), loss = 8.983727 (173.264 sec/epoch), lr: 0.001000\nmi: 0.3259040292163023\n2024-03-19 11:33:04.929349: step 24544/47200 (epoch 52/100), loss = 8.970987 (173.327 sec/epoch), lr: 0.001000\nmi: 0.32302527845663503\n2024-03-19 11:35:58.266224: step 25016/47200 (epoch 53/100), loss = 8.957589 (173.337 sec/epoch), lr: 0.001000\nmi: 0.32012371850215776\n2024-03-19 11:38:51.687173: step 25488/47200 (epoch 54/100), loss = 8.944075 (173.421 sec/epoch), lr: 0.001000\nmi: 0.3179245140150946\n2024-03-19 11:41:45.020623: step 25960/47200 (epoch 55/100), loss = 8.930952 (173.333 sec/epoch), lr: 0.001000\nmi: 0.3147717473239211\nEvaluating on dev set...\n.....................................................................\nval epoch:55, time: 9656.791144(s), X (MRR: 0.3178, NDCG@10: 0.3610, HR@10: 0.5399), Y (MRR: 0.3766, NDCG@10: 0.4109, HR@10: 0.5591)\n...................................................................\nX best!\n[0.3253336365240881, 0.3358965573918013, 0.36989989315799326, 0.21226309921962097, 0.44905239687848386, 0.5538461538461539]\nY best!\n[0.3883900725466136, 0.3999280854262212, 0.42467449576170374, 0.2882608695652174, 0.49869565217391304, 0.5752173913043478]\n2024-03-19 11:44:47.537852: step 26432/47200 (epoch 56/100), loss = 8.917639 (173.442 sec/epoch), lr: 0.001000\nmi: 0.31277739700498236\n2024-03-19 11:47:40.873901: step 26904/47200 (epoch 57/100), loss = 8.904396 (173.336 sec/epoch), lr: 0.001000\nmi: 0.30943994239856637\n2024-03-19 11:50:34.310500: step 27376/47200 (epoch 58/100), loss = 8.892387 (173.436 sec/epoch), lr: 0.001000\nmi: 0.3076010379498288\n2024-03-19 11:53:27.649141: step 27848/47200 (epoch 59/100), loss = 8.879401 (173.338 sec/epoch), lr: 0.001000\nmi: 0.30564266020211106\n2024-03-19 11:59:23.541947: step 28792/47200 (epoch 61/100), loss = 8.853273 (173.330 sec/epoch), lr: 0.001000\nmi: 0.3004963350308651\n2024-03-19 12:02:16.848190: step 29264/47200 (epoch 62/100), loss = 8.841361 (173.306 sec/epoch), lr: 0.001000\nmi: 0.29755920652236956\n2024-03-19 12:05:10.195349: step 29736/47200 (epoch 63/100), loss = 8.830406 (173.347 sec/epoch), lr: 0.001000\nmi: 0.29650025661340196\n2024-03-19 12:08:03.593068: step 30208/47200 (epoch 64/100), loss = 8.817382 (173.398 sec/epoch), lr: 0.001000\nmi: 0.2929983722898416\n2024-03-19 12:10:57.488562: step 30680/47200 (epoch 65/100), loss = 8.804076 (173.895 sec/epoch), lr: 0.001000\nmi: 0.2913146797757028\nEvaluating on dev set...\n.....................................................................\nval epoch:65, time: 11409.287543(s), X (MRR: 0.3243, NDCG@10: 0.3681, HR@10: 0.5481), Y (MRR: 0.3858, NDCG@10: 0.4222, HR@10: 0.5749)\n...................................................................\nX best!\n[0.33343944715356516, 0.34368239355802904, 0.3793848571046291, 0.2214046822742475, 0.4564102564102564, 0.5665551839464883]\nY best!\n[0.3998582957143986, 0.4109880211607472, 0.4360465887523666, 0.3008695652173913, 0.5082608695652174, 0.5852173913043478]\n2024-03-19 12:13:59.979204: step 31152/47200 (epoch 66/100), loss = 8.793425 (173.375 sec/epoch), lr: 0.001000\nmi: 0.2899023043339028\n2024-03-19 12:16:53.517140: step 31624/47200 (epoch 67/100), loss = 8.781842 (173.538 sec/epoch), lr: 0.001000\nmi: 0.28704234273251855\n2024-03-19 12:19:47.296592: step 32096/47200 (epoch 68/100), loss = 8.769842 (173.779 sec/epoch), lr: 0.001000\nmi: 0.2852213684343177\n2024-03-19 12:22:40.672439: step 32568/47200 (epoch 69/100), loss = 8.758184 (173.376 sec/epoch), lr: 0.001000\nmi: 0.2835549871547748\n2024-03-19 12:25:34.302415: step 33040/47200 (epoch 70/100), loss = 8.745379 (173.630 sec/epoch), lr: 0.001000\nmi: 0.27996365551726304\nEvaluating on dev set...\n.....................................................................\nval epoch:70, time: 12286.056298(s), X (MRR: 0.3272, NDCG@10: 0.3713, HR@10: 0.5523), Y (MRR: 0.3882, NDCG@10: 0.4256, HR@10: 0.5807)\n...................................................................\nX best!\n[0.33608920944415727, 0.34717135390601017, 0.38206237282118366, 0.22385730211817167, 0.4617614269788183, 0.5694537346711259]\nY best!\n[0.4038716382038742, 0.4146221242879051, 0.44096212928616196, 0.3056521739130435, 0.5113043478260869, 0.5921739130434782]\n2024-03-19 12:28:37.159091: step 33512/47200 (epoch 71/100), loss = 8.735095 (173.800 sec/epoch), lr: 0.001000\nmi: 0.278980881196715\n2024-03-19 12:31:30.822703: step 33984/47200 (epoch 72/100), loss = 8.725168 (173.663 sec/epoch), lr: 0.001000\nmi: 0.27742792580087305\n2024-03-19 12:34:24.439121: step 34456/47200 (epoch 73/100), loss = 8.711232 (173.616 sec/epoch), lr: 0.001000\nmi: 0.2730499095141385\n2024-03-19 12:37:18.097872: step 34928/47200 (epoch 74/100), loss = 8.700560 (173.659 sec/epoch), lr: 0.001000\nmi: 0.2732476514906199\n2024-03-19 12:40:11.735372: step 35400/47200 (epoch 75/100), loss = 8.689279 (173.637 sec/epoch), lr: 0.001000\nmi: 0.27066456172930997\nEvaluating on dev set...\n.....................................................................\nval epoch:75, time: 13163.515308(s), X (MRR: 0.3290, NDCG@10: 0.3738, HR@10: 0.5567), Y (MRR: 0.3922, NDCG@10: 0.4292, HR@10: 0.5832)\n...................................................................\nX best!\n[0.33865933127350945, 0.3492369522298726, 0.38505979448994354, 0.2258639910813824, 0.4633221850613155, 0.5734671125975473]\nY best!\n[0.408314829354261, 0.4207590608070628, 0.4456235435598679, 0.3091304347826087, 0.52, 0.5965217391304348]\n2024-03-19 12:43:14.346954: step 35872/47200 (epoch 76/100), loss = 8.680666 (173.533 sec/epoch), lr: 0.001000\nmi: 0.26964925888104974\n2024-03-19 12:46:07.962311: step 36344/47200 (epoch 77/100), loss = 8.667454 (173.615 sec/epoch), lr: 0.001000\nmi: 0.2661841914941699\n2024-03-19 12:49:01.576408: step 36816/47200 (epoch 78/100), loss = 8.657784 (173.614 sec/epoch), lr: 0.001000\nmi: 0.2651805654799537\n2024-03-19 12:51:55.215334: step 37288/47200 (epoch 79/100), loss = 8.646701 (173.639 sec/epoch), lr: 0.001000\nmi: 0.263217160465606\n2024-03-19 12:57:51.283140: step 38232/47200 (epoch 81/100), loss = 8.626983 (173.531 sec/epoch), lr: 0.001000\nmi: 0.2595578414403785\n2024-03-19 13:00:44.923814: step 38704/47200 (epoch 82/100), loss = 8.615549 (173.641 sec/epoch), lr: 0.001000\nmi: 0.2570320975351133\n2024-03-19 13:03:38.611683: step 39176/47200 (epoch 83/100), loss = 8.604979 (173.688 sec/epoch), lr: 0.001000\nmi: 0.2552059590563937\n2024-03-19 13:06:32.242625: step 39648/47200 (epoch 84/100), loss = 8.596540 (173.631 sec/epoch), lr: 0.001000\nmi: 0.25455096011065864\n2024-03-19 13:09:25.845546: step 40120/47200 (epoch 85/100), loss = 8.585159 (173.603 sec/epoch), lr: 0.001000\nmi: 0.25101658413975936\nEvaluating on dev set...\n.....................................................................\nval epoch:85, time: 14917.634915(s), X (MRR: 0.3365, NDCG@10: 0.3809, HR@10: 0.5629), Y (MRR: 0.3999, NDCG@10: 0.4398, HR@10: 0.6007)\n...................................................................\nX best!\n[0.34307726541588857, 0.3547513559720223, 0.39008037609628204, 0.22831661092530658, 0.4711259754738016, 0.5801560758082497]\nY best!\n[0.41205368792699937, 0.42586747001152475, 0.4502248211048884, 0.31043478260869567, 0.5282608695652173, 0.6034782608695652]\n2024-03-19 13:15:22.294932: step 41064/47200 (epoch 87/100), loss = 8.567056 (173.744 sec/epoch), lr: 0.001000\nmi: 0.2494570887095091\n2024-03-19 13:18:16.135303: step 41536/47200 (epoch 88/100), loss = 8.556904 (173.840 sec/epoch), lr: 0.001000\nmi: 0.24726559437053672\n2024-03-19 13:21:10.145995: step 42008/47200 (epoch 89/100), loss = 8.546104 (174.011 sec/epoch), lr: 0.001000\nmi: 0.2443532335524588\n2024-03-19 13:24:03.927752: step 42480/47200 (epoch 90/100), loss = 8.537214 (173.782 sec/epoch), lr: 0.001000\nmi: 0.24282934297886463\nEvaluating on dev set...\n.....................................................................\nval epoch:90, time: 15795.699809(s), X (MRR: 0.3396, NDCG@10: 0.3849, HR@10: 0.5688), Y (MRR: 0.4048, NDCG@10: 0.4445, HR@10: 0.6044)\n...................................................................\nX best!\n[0.34473749552727095, 0.35631868555135415, 0.39230371044020274, 0.22920847268673356, 0.4729096989966555, 0.5839464882943144]\nY best!\n[0.41639646312837153, 0.43046259259542974, 0.455257246463299, 0.31478260869565217, 0.5330434782608696, 0.61]\n2024-03-19 13:27:06.979595: step 42952/47200 (epoch 91/100), loss = 8.527311 (173.964 sec/epoch), lr: 0.001000\nmi: 0.2405635651264151\n2024-03-19 13:30:00.749691: step 43424/47200 (epoch 92/100), loss = 8.518703 (173.770 sec/epoch), lr: 0.001000\nmi: 0.23972261141417384\n2024-03-19 13:32:54.714938: step 43896/47200 (epoch 93/100), loss = 8.508942 (173.965 sec/epoch), lr: 0.001000\nmi: 0.23742655340140156\n2024-03-19 13:35:48.579609: step 44368/47200 (epoch 94/100), loss = 8.501964 (173.865 sec/epoch), lr: 0.001000\nmi: 0.23659623407964\n2024-03-19 13:38:42.529447: step 44840/47200 (epoch 95/100), loss = 8.493504 (173.950 sec/epoch), lr: 0.001000\nmi: 0.23603835131152193\nEvaluating on dev set...\n.....................................................................\nval epoch:95, time: 16674.292338(s), X (MRR: 0.3413, NDCG@10: 0.3865, HR@10: 0.5708), Y (MRR: 0.4077, NDCG@10: 0.4478, HR@10: 0.6086)\n...................................................................\nX best!\n[0.34587354736967124, 0.35859555068141913, 0.3936710456496347, 0.2294314381270903, 0.47736900780379043, 0.585953177257525]\nY best!\n[0.41924482317577827, 0.4323377602862784, 0.45811110001080313, 0.3169565217391304, 0.5330434782608696, 0.6130434782608696]\n2024-03-19 13:41:45.500984: step 45312/47200 (epoch 96/100), loss = 8.484568 (173.919 sec/epoch), lr: 0.001000\nmi: 0.23320336201370256\n2024-03-19 13:44:39.383871: step 45784/47200 (epoch 97/100), loss = 8.475840 (173.883 sec/epoch), lr: 0.001000\nmi: 0.231466556353084\n2024-03-19 13:47:33.399758: step 46256/47200 (epoch 98/100), loss = 8.468645 (174.016 sec/epoch), lr: 0.001000\nmi: 0.23099493774569654\n2024-03-19 13:50:27.308622: step 46728/47200 (epoch 99/100), loss = 8.458161 (173.909 sec/epoch), lr: 0.001000\nmi: 0.22939149003981008\n2024-03-19 13:53:21.305088: step 47200/47200 (epoch 100/100), loss = 8.449768 (173.996 sec/epoch), lr: 0.001000\nmi: 0.22701324344123322\nEvaluating on dev set...\n.....................................................................\nval epoch:100, time: 17553.137872(s), X (MRR: 0.3429, NDCG@10: 0.3883, HR@10: 0.5730), Y (MRR: 0.4102, NDCG@10: 0.4510, HR@10: 0.6136)\n...................................................................\nX best!\n[0.34759222428123976, 0.3604095083691694, 0.3951705170186845, 0.23121516164994427, 0.4793756967670011, 0.586845039018952]\nY best!\n[0.4210132321457958, 0.43342284204425907, 0.45954008644544414, 0.31956521739130433, 0.5330434782608696, 0.6139130434782609]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}